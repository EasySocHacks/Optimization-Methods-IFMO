{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from HW2.benchmark_proceeder import BenchmarkStorage\n",
    "from HW2.error_calculator import *\n",
    "from HW2.regression_generator import generate_regression\n",
    "from HW2.sgd import sgd, minibatch_gd, gd\n",
    "from HW2.visualization import visualize_regression_point, visualize_line, draw_levels\n",
    "from HW2.optimization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f, points, f_ab = generate_regression(f_scale=50, point_count=500, scale=np.array([3, 10]))\n",
    "\n",
    "visualize_regression_point(f, points, scale=3)\n",
    "\n",
    "storage = BenchmarkStorage()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "errors = [AbsErrorCalculator(), SquaredErrorCalculator(), BoxErrorCalculator()]\n",
    "optimizators = [DefaultOptimization(), MomentumOptimization(0.95), NesterovOptimization(0.95), AdaGradOptimization(),\n",
    "                RMSPropOptimization(0.5), AdamOptimization()]\n",
    "\n",
    "batch_sizes = [1, 10, 40, len(points)]\n",
    "\n",
    "result = np.array([])\n",
    "for error in tqdm(errors, \"Errors\", position=0):\n",
    "    for optimizator in tqdm(optimizators, \"Optimizations\", position=1):\n",
    "        for batch_size in tqdm(batch_sizes, \"Batch sizes\", position=2):\n",
    "\n",
    "            index = storage.add_benchmark_config(batch_size=str(batch_size), optimiser=optimizator, error=error)\n",
    "            for _ in range(20 if batch_size != len(points) else 1):\n",
    "                ab, meta = minibatch_gd(points, batch_size=batch_size, error=error,\n",
    "                                        optimization=optimizator)\n",
    "                storage.add_benchmark_result(index, meta)\n",
    "            result = np.append(result, storage.get_benchmark_results_arrayed(index))\n",
    "\n",
    "result = result.reshape((-1, 8))\n",
    "df = pd.DataFrame(result, columns=[\n",
    "    'Config',\n",
    "    'Mean time',\n",
    "    'Mean mem',\n",
    "    'Mean SMAPE',\n",
    "    'Mean RMSE',\n",
    "    'Mean logcosh',\n",
    "    'Mean gradient calls',\n",
    "    'Mean iterations'\n",
    "])\n",
    "df.to_csv(\"data/2.4.csv\", sep='\\t')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f, points, f_ab = generate_regression(f_scale=50, point_count=500, scale=np.array([3, 3, 10]))\n",
    "\n",
    "print(f_ab)\n",
    "\n",
    "storage = BenchmarkStorage()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "errors = [AbsErrorCalculator(), SquaredErrorCalculator(), BoxErrorCalculator()]\n",
    "optimizators = [DefaultOptimization(), MomentumOptimization(0.95), NesterovOptimization(0.95), AdaGradOptimization(),\n",
    "                RMSPropOptimization(0.5), AdamOptimization()]\n",
    "\n",
    "batch_sizes = [1, 10, 40, len(points)]\n",
    "\n",
    "result = np.array([])\n",
    "for error in tqdm(errors, \"Errors\", position=0):\n",
    "    for optimizator in tqdm(optimizators, \"Optimizations\", position=1):\n",
    "        for batch_size in tqdm(batch_sizes, \"Batch sizes\", position=2):\n",
    "\n",
    "            index = storage.add_benchmark_config(batch_size=str(batch_size), optimiser=optimizator, error=error)\n",
    "            for _ in range(20 if batch_size != len(points) else 1):\n",
    "                ab, meta = minibatch_gd(points, batch_size=batch_size, error=error,\n",
    "                                        optimization=optimizator)\n",
    "                storage.add_benchmark_result(index, meta)\n",
    "            result = np.append(result, storage.get_benchmark_results_arrayed(index))\n",
    "\n",
    "result = result.reshape((-1, 8))\n",
    "df = pd.DataFrame(result, columns=[\n",
    "    'Config',\n",
    "    'Mean time',\n",
    "    'Mean mem',\n",
    "    'Mean SMAPE',\n",
    "    'Mean RMSE',\n",
    "    'Mean logcosh',\n",
    "    'Mean gradient calls',\n",
    "    'Mean iterations'\n",
    "])\n",
    "df.to_csv(\"data/2.4.csv\", sep='\\t')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "scale = np.array([10])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "dims:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eaf0a1257bd64ef190522a0b1c157ee7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                               Config Mean time Mean mem  \\\n0   (sgd_1, 1, Default(no) optimization, Squared e...  0.217872  -2.46kB   \n1   (sgd_2, 1, Default(no) optimization, Squared e...  0.195474     0.0B   \n2   (sgd_3, 1, Default(no) optimization, Squared e...  0.178408     0.0B   \n3   (sgd_4, 1, Default(no) optimization, Squared e...  0.147833     0.0B   \n4   (sgd_5, 1, Default(no) optimization, Squared e...  0.109032     0.0B   \n5   (sgd_6, 1, Default(no) optimization, Squared e...  0.177815     0.0B   \n6   (sgd_7, 1, Default(no) optimization, Squared e...  0.172792     0.0B   \n7   (sgd_8, 1, Default(no) optimization, Squared e...  0.129602     0.0B   \n8   (sgd_9, 1, Default(no) optimization, Squared e...  0.098811     0.0B   \n9   (sgd_10, 1, Default(no) optimization, Squared ...  0.138816     0.0B   \n10  (sgd_11, 1, Default(no) optimization, Squared ...  0.134395     0.0B   \n11  (sgd_12, 1, Default(no) optimization, Squared ...  0.148564     0.0B   \n12  (sgd_13, 1, Default(no) optimization, Squared ...  0.183613     0.0B   \n13  (sgd_14, 1, Default(no) optimization, Squared ...  0.145608     0.0B   \n14  (sgd_15, 1, Default(no) optimization, Squared ...  0.179799     0.0B   \n15  (sgd_16, 1, Default(no) optimization, Squared ...  0.085388     0.0B   \n16  (sgd_17, 1, Default(no) optimization, Squared ...  0.163156     0.0B   \n17  (sgd_18, 1, Default(no) optimization, Squared ...  0.175429     0.0B   \n18  (sgd_19, 1, Default(no) optimization, Squared ...  0.163638     0.0B   \n19  (sgd_20, 1, Default(no) optimization, Squared ...   0.10681     0.0B   \n\n   Mean SMAPE  Mean RMSE Mean logcosh Mean gradient calls Mean iterations  \n0    0.126573  10.153866      7.53136             2016.85         2016.85  \n1    0.134058    9.82535     7.267549              1836.2          1836.2  \n2    0.152512  10.830035      7.89475              1873.7          1873.7  \n3    0.125476   9.737605     7.005091             1407.15         1407.15  \n4     0.16259  10.328972     7.589657              1165.0          1165.0  \n5    0.108549  10.211665     7.562015              1740.8          1740.8  \n6     0.12718  10.082684     7.413604             1773.35         1773.35  \n7    0.188045    9.87262     7.217659             1273.95         1273.95  \n8    0.192014  10.153849     7.298387             1014.95         1014.95  \n9    0.146857  10.298861     7.475521              1394.2          1394.2  \n10   0.141395  10.480425     7.694963             1335.15         1335.15  \n11   0.130333  10.283669     7.353527             1461.75         1461.75  \n12   0.163654   9.381024     6.848088             1881.35         1881.35  \n13   0.159243  10.282122     7.547353             1504.55         1504.55  \n14   0.118856  10.356466      7.52276             1621.75         1621.75  \n15    0.37434  10.271217       7.3783               827.1           827.1  \n16   0.130017  10.238963      7.63355             1502.35         1502.35  \n17   0.164424   10.18049     7.520531              1617.3          1617.3  \n18   0.111717  10.175435     7.280792             1598.15         1598.15  \n19   0.190659  10.188582      7.39302             1064.95         1064.95  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Config</th>\n      <th>Mean time</th>\n      <th>Mean mem</th>\n      <th>Mean SMAPE</th>\n      <th>Mean RMSE</th>\n      <th>Mean logcosh</th>\n      <th>Mean gradient calls</th>\n      <th>Mean iterations</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(sgd_1, 1, Default(no) optimization, Squared e...</td>\n      <td>0.217872</td>\n      <td>-2.46kB</td>\n      <td>0.126573</td>\n      <td>10.153866</td>\n      <td>7.53136</td>\n      <td>2016.85</td>\n      <td>2016.85</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(sgd_2, 1, Default(no) optimization, Squared e...</td>\n      <td>0.195474</td>\n      <td>0.0B</td>\n      <td>0.134058</td>\n      <td>9.82535</td>\n      <td>7.267549</td>\n      <td>1836.2</td>\n      <td>1836.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(sgd_3, 1, Default(no) optimization, Squared e...</td>\n      <td>0.178408</td>\n      <td>0.0B</td>\n      <td>0.152512</td>\n      <td>10.830035</td>\n      <td>7.89475</td>\n      <td>1873.7</td>\n      <td>1873.7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(sgd_4, 1, Default(no) optimization, Squared e...</td>\n      <td>0.147833</td>\n      <td>0.0B</td>\n      <td>0.125476</td>\n      <td>9.737605</td>\n      <td>7.005091</td>\n      <td>1407.15</td>\n      <td>1407.15</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(sgd_5, 1, Default(no) optimization, Squared e...</td>\n      <td>0.109032</td>\n      <td>0.0B</td>\n      <td>0.16259</td>\n      <td>10.328972</td>\n      <td>7.589657</td>\n      <td>1165.0</td>\n      <td>1165.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>(sgd_6, 1, Default(no) optimization, Squared e...</td>\n      <td>0.177815</td>\n      <td>0.0B</td>\n      <td>0.108549</td>\n      <td>10.211665</td>\n      <td>7.562015</td>\n      <td>1740.8</td>\n      <td>1740.8</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>(sgd_7, 1, Default(no) optimization, Squared e...</td>\n      <td>0.172792</td>\n      <td>0.0B</td>\n      <td>0.12718</td>\n      <td>10.082684</td>\n      <td>7.413604</td>\n      <td>1773.35</td>\n      <td>1773.35</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>(sgd_8, 1, Default(no) optimization, Squared e...</td>\n      <td>0.129602</td>\n      <td>0.0B</td>\n      <td>0.188045</td>\n      <td>9.87262</td>\n      <td>7.217659</td>\n      <td>1273.95</td>\n      <td>1273.95</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>(sgd_9, 1, Default(no) optimization, Squared e...</td>\n      <td>0.098811</td>\n      <td>0.0B</td>\n      <td>0.192014</td>\n      <td>10.153849</td>\n      <td>7.298387</td>\n      <td>1014.95</td>\n      <td>1014.95</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>(sgd_10, 1, Default(no) optimization, Squared ...</td>\n      <td>0.138816</td>\n      <td>0.0B</td>\n      <td>0.146857</td>\n      <td>10.298861</td>\n      <td>7.475521</td>\n      <td>1394.2</td>\n      <td>1394.2</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>(sgd_11, 1, Default(no) optimization, Squared ...</td>\n      <td>0.134395</td>\n      <td>0.0B</td>\n      <td>0.141395</td>\n      <td>10.480425</td>\n      <td>7.694963</td>\n      <td>1335.15</td>\n      <td>1335.15</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>(sgd_12, 1, Default(no) optimization, Squared ...</td>\n      <td>0.148564</td>\n      <td>0.0B</td>\n      <td>0.130333</td>\n      <td>10.283669</td>\n      <td>7.353527</td>\n      <td>1461.75</td>\n      <td>1461.75</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>(sgd_13, 1, Default(no) optimization, Squared ...</td>\n      <td>0.183613</td>\n      <td>0.0B</td>\n      <td>0.163654</td>\n      <td>9.381024</td>\n      <td>6.848088</td>\n      <td>1881.35</td>\n      <td>1881.35</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>(sgd_14, 1, Default(no) optimization, Squared ...</td>\n      <td>0.145608</td>\n      <td>0.0B</td>\n      <td>0.159243</td>\n      <td>10.282122</td>\n      <td>7.547353</td>\n      <td>1504.55</td>\n      <td>1504.55</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>(sgd_15, 1, Default(no) optimization, Squared ...</td>\n      <td>0.179799</td>\n      <td>0.0B</td>\n      <td>0.118856</td>\n      <td>10.356466</td>\n      <td>7.52276</td>\n      <td>1621.75</td>\n      <td>1621.75</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>(sgd_16, 1, Default(no) optimization, Squared ...</td>\n      <td>0.085388</td>\n      <td>0.0B</td>\n      <td>0.37434</td>\n      <td>10.271217</td>\n      <td>7.3783</td>\n      <td>827.1</td>\n      <td>827.1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>(sgd_17, 1, Default(no) optimization, Squared ...</td>\n      <td>0.163156</td>\n      <td>0.0B</td>\n      <td>0.130017</td>\n      <td>10.238963</td>\n      <td>7.63355</td>\n      <td>1502.35</td>\n      <td>1502.35</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>(sgd_18, 1, Default(no) optimization, Squared ...</td>\n      <td>0.175429</td>\n      <td>0.0B</td>\n      <td>0.164424</td>\n      <td>10.18049</td>\n      <td>7.520531</td>\n      <td>1617.3</td>\n      <td>1617.3</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>(sgd_19, 1, Default(no) optimization, Squared ...</td>\n      <td>0.163638</td>\n      <td>0.0B</td>\n      <td>0.111717</td>\n      <td>10.175435</td>\n      <td>7.280792</td>\n      <td>1598.15</td>\n      <td>1598.15</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>(sgd_20, 1, Default(no) optimization, Squared ...</td>\n      <td>0.10681</td>\n      <td>0.0B</td>\n      <td>0.190659</td>\n      <td>10.188582</td>\n      <td>7.39302</td>\n      <td>1064.95</td>\n      <td>1064.95</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.array([])\n",
    "\n",
    "for i in tqdm(range(20), \"dims\"):\n",
    "    np.append([3], scale)\n",
    "    f, points, f_ab = generate_regression(f_scale=50, point_count=500, scale=np.array([3, 3, 10]))\n",
    "    index = storage.add_benchmark_config(batch_size='sgd_{}'.format(i + 1))\n",
    "    for _ in range(20):\n",
    "        ab, meta = sgd(points)\n",
    "        storage.add_benchmark_result(index, meta)\n",
    "    result = np.append(result, storage.get_benchmark_results_arrayed(index))\n",
    "result = result.reshape((-1, 8))\n",
    "\n",
    "df = pd.DataFrame(result, columns=[\n",
    "    'Config',\n",
    "    'Mean time',\n",
    "    'Mean mem',\n",
    "    'Mean SMAPE',\n",
    "    'Mean RMSE',\n",
    "    'Mean logcosh',\n",
    "    'Mean gradient calls',\n",
    "    'Mean iterations'\n",
    "])\n",
    "df.to_csv(\"data/2.4_ndims.csv\", sep='\\t')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}